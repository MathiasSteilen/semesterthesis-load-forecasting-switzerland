{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import plotnine as pn\n",
    "import matplotlib.pyplot as plt\n",
    "from mizani.formatters import comma_format, custom_format, currency_format, percent_format\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rc\n",
    "import plotly.express as px\n",
    "\n",
    "# Utils\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import yaml\n",
    "import warnings\n",
    "import time\n",
    "import holidays\n",
    "import pickle\n",
    "\n",
    "# Modelling\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    FunctionTransformer,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    root_mean_squared_error,\n",
    "    mean_squared_error\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import FeatureUnion, make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller, kpss\n",
    "\n",
    "from statsforecast.models import AutoARIMA, ARIMA\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "\n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "\n",
    "rc('text', usetex=False)\n",
    "\n",
    "jama_colour = [\n",
    "    \"#374e55\",\n",
    "    \"#df8f44\",\n",
    "    \"#00a1d5\",\n",
    "    \"#b24745\",\n",
    "    \"#79af97\",\n",
    "    \"#6a6599\",\n",
    "    \"#80796b\",\n",
    "]\n",
    "\n",
    "pd.set_option(\"display.max.columns\", 500)\n",
    "pd.set_option(\"display.max.columns\", 500)\n",
    "\n",
    "\n",
    "theme_academic = pn.theme(\n",
    "    text=pn.element_text(family=\"Latin Modern Roman\"),\n",
    "    plot_title=pn.element_text(weight=\"bold\", size=14, ha=\"center\"),\n",
    "    legend_text=pn.element_text(size=9),  # Smaller font for legend items\n",
    "    panel_background=pn.element_rect(fill=\"white\"),  # Clean white background\n",
    "    panel_border=pn.element_rect(color=\"grey\", size=0.5),\n",
    "    axis_ticks=pn.element_line(color=\"grey\"),\n",
    "    panel_grid_major=pn.element_line(color=\"grey\", size=0.1, alpha=0.3),\n",
    "    panel_grid_minor=pn.element_line(color=\"grey\", size=0.1, alpha=0.3),\n",
    "    legend_background=pn.element_rect(fill=\"white\", color=None),\n",
    "    legend_key=pn.element_rect(fill=\"white\", color=None),\n",
    "    plot_margin=0.02,\n",
    "    figure_size=(6, 4),  # Set default figure size (width, height in inches)\n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\n",
    "    \"../0_data/preprocessed/df_final_reduced.csv\", try_parse_dates=True\n",
    ").filter(pl.col(\"datetime\") >= pd.Timestamp(\"2021-09-01 00:00\"))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "\n",
    "Just forward fill for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fill_null(strategy=\"forward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lags\n",
    "\n",
    "Include target variable lags.\n",
    "\n",
    "- Same hour on previous day\n",
    "- Average consumption during the past week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exogenous Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling features:\n",
    "\n",
    "- 7d average:\n",
    "    - Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_features_7d = (\n",
    "    df.select(\"datetime\", \"Zurich_soil_temperature_7_to_28cm\")\n",
    "    .with_columns(\n",
    "        temp_rolling=pl.col(\"Zurich_soil_temperature_7_to_28cm\").rolling_mean(24 * 7),\n",
    "        datetime=pl.col(\"datetime\").dt.offset_by(\"1d\"),\n",
    "    )\n",
    "    .drop(\"Zurich_soil_temperature_7_to_28cm\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(rolling_features_7d, how=\"left\", on=\"datetime\", coalesce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"datetime\"] - df[\"datetime\"].shift(1)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calendar Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    day_of_month=pl.col(\"datetime\").dt.day(),\n",
    "    day_of_year=pl.col(\"datetime\").dt.ordinal_day(),\n",
    "    day_of_week=pl.col(\"datetime\").dt.weekday(),\n",
    "    month=pl.col(\"datetime\").dt.month(),\n",
    "    hour=pl.col(\"datetime\").dt.hour(),\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the region (Canton of Berne) and the country (Switzerland)\n",
    "country = \"CH\"\n",
    "prov = \"ZH\"\n",
    "\n",
    "# Create a list of the regional holidays for the canton of Berne\n",
    "regional_holidays = holidays.CH(\n",
    "    years=df[\"datetime\"].dt.year().unique().to_list(), prov=prov\n",
    ")\n",
    "\n",
    "holiday_df = pl.DataFrame(\n",
    "    {\n",
    "        \"holiday_name\": list(regional_holidays.values()),\n",
    "        \"holiday_date\": list(regional_holidays.keys()),\n",
    "    }\n",
    ").sort(\"holiday_date\")\n",
    "\n",
    "holiday_df[\"holiday_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define holiday names\n",
    "holiday_names = [\n",
    "    # Osterferienzeit (Easter Holiday Season)\n",
    "    \"Osterferienzeit_1\",\n",
    "    \"Osterferienzeit_2\",\n",
    "    \"Osterferienzeit_3\",\n",
    "    \"Osterferienzeit_4\",\n",
    "    \"Osterferienzeit_5\",\n",
    "    # Auffahrtferienzeit (Ascension Holiday Season)\n",
    "    \"Auffahrtferienzeit_1\",\n",
    "    \"Auffahrtferienzeit_2\",\n",
    "    \"Auffahrtferienzeit_3\",\n",
    "    \"Auffahrtferienzeit_4\",\n",
    "    \"Auffahrtferienzeit_5\",\n",
    "]\n",
    "\n",
    "# Repeat holiday names for each year\n",
    "holiday_names_full = holiday_names * 4\n",
    "\n",
    "# Define holiday dates\n",
    "holiday_dates = [\n",
    "    # 2021\n",
    "    \"2021-03-31\",\n",
    "    \"2021-04-01\",\n",
    "    \"2021-04-02\",\n",
    "    \"2021-04-03\",\n",
    "    \"2021-04-04\",\n",
    "    \"2021-05-12\",\n",
    "    \"2021-05-13\",\n",
    "    \"2021-05-14\",\n",
    "    \"2021-05-15\",\n",
    "    \"2021-05-16\",\n",
    "    # 2022\n",
    "    \"2022-04-13\",\n",
    "    \"2022-04-14\",\n",
    "    \"2022-04-15\",\n",
    "    \"2022-04-16\",\n",
    "    \"2022-04-17\",\n",
    "    \"2022-05-25\",\n",
    "    \"2022-05-26\",\n",
    "    \"2022-05-27\",\n",
    "    \"2022-05-28\",\n",
    "    \"2022-05-29\",\n",
    "    # 2023\n",
    "    \"2023-04-05\",\n",
    "    \"2023-04-06\",\n",
    "    \"2023-04-07\",\n",
    "    \"2023-04-08\",\n",
    "    \"2023-04-09\",\n",
    "    \"2023-05-17\",\n",
    "    \"2023-05-18\",\n",
    "    \"2023-05-19\",\n",
    "    \"2023-05-20\",\n",
    "    \"2023-05-21\",\n",
    "    # 2024\n",
    "    \"2024-03-27\",\n",
    "    \"2024-03-28\",\n",
    "    \"2024-03-29\",\n",
    "    \"2024-03-30\",\n",
    "    \"2024-03-31\",\n",
    "    \"2024-05-08\",\n",
    "    \"2024-05-09\",\n",
    "    \"2024-05-10\",\n",
    "    \"2024-05-11\",\n",
    "    \"2024-05-12\",\n",
    "]\n",
    "\n",
    "# Create the DataFrame\n",
    "holiday_manual_df = pl.DataFrame(\n",
    "    {\n",
    "        \"holiday_name\": holiday_names_full,\n",
    "        \"holiday_date\": holiday_dates,\n",
    "    }\n",
    ").with_columns(\n",
    "    pl.col(\"holiday_date\").str.to_date()\n",
    ")  # Define holiday names\n",
    "holiday_names = [\n",
    "    # Osterferienzeit (Easter Holiday Season)\n",
    "    \"Osterferienzeit_1\",\n",
    "    \"Osterferienzeit_2\",\n",
    "    \"Osterferienzeit_3\",\n",
    "    \"Osterferienzeit_4\",\n",
    "    \"Osterferienzeit_5\",\n",
    "    # Auffahrtferienzeit (Ascension Holiday Season)\n",
    "    \"Auffahrtferienzeit_1\",\n",
    "    \"Auffahrtferienzeit_2\",\n",
    "    \"Auffahrtferienzeit_3\",\n",
    "    \"Auffahrtferienzeit_4\",\n",
    "    \"Auffahrtferienzeit_5\",\n",
    "]\n",
    "\n",
    "# Repeat holiday names for each year\n",
    "holiday_names_full = holiday_names * 4\n",
    "\n",
    "# Define holiday dates\n",
    "holiday_dates = [\n",
    "    # 2021\n",
    "    \"2021-03-31\",\n",
    "    \"2021-04-01\",\n",
    "    \"2021-04-02\",\n",
    "    \"2021-04-03\",\n",
    "    \"2021-04-04\",\n",
    "    \"2021-05-12\",\n",
    "    \"2021-05-13\",\n",
    "    \"2021-05-14\",\n",
    "    \"2021-05-15\",\n",
    "    \"2021-05-16\",\n",
    "    # 2022\n",
    "    \"2022-04-13\",\n",
    "    \"2022-04-14\",\n",
    "    \"2022-04-15\",\n",
    "    \"2022-04-16\",\n",
    "    \"2022-04-17\",\n",
    "    \"2022-05-25\",\n",
    "    \"2022-05-26\",\n",
    "    \"2022-05-27\",\n",
    "    \"2022-05-28\",\n",
    "    \"2022-05-29\",\n",
    "    # 2023\n",
    "    \"2023-04-05\",\n",
    "    \"2023-04-06\",\n",
    "    \"2023-04-07\",\n",
    "    \"2023-04-08\",\n",
    "    \"2023-04-09\",\n",
    "    \"2023-05-17\",\n",
    "    \"2023-05-18\",\n",
    "    \"2023-05-19\",\n",
    "    \"2023-05-20\",\n",
    "    \"2023-05-21\",\n",
    "    # 2024\n",
    "    \"2024-03-27\",\n",
    "    \"2024-03-28\",\n",
    "    \"2024-03-29\",\n",
    "    \"2024-03-30\",\n",
    "    \"2024-03-31\",\n",
    "    \"2024-05-08\",\n",
    "    \"2024-05-09\",\n",
    "    \"2024-05-10\",\n",
    "    \"2024-05-11\",\n",
    "    \"2024-05-12\",\n",
    "]\n",
    "\n",
    "# Create the DataFrame\n",
    "holiday_manual_df = pl.DataFrame(\n",
    "    {\n",
    "        \"holiday_name\": holiday_names_full,\n",
    "        \"holiday_date\": holiday_dates,\n",
    "    }\n",
    ").with_columns(pl.col(\"holiday_date\").str.to_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df = (\n",
    "    pl.concat(\n",
    "        [\n",
    "            holiday_df,\n",
    "            holiday_manual_df,\n",
    "        ],\n",
    "        how=\"vertical\",\n",
    "    )\n",
    "    .sort(\"holiday_date\")\n",
    "    .unique(\"holiday_date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.with_columns(date=pl.col(\"datetime\").dt.date())\n",
    "    .join(holiday_df, how=\"left\", left_on=\"date\", right_on=\"holiday_date\")\n",
    "    .drop(\"date\")\n",
    "    .with_columns(holiday_name=pl.col(\"holiday_name\").fill_null(\"no_holiday\"))\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "\n",
    "\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))\n",
    "\n",
    "\n",
    "def encode_cyclically(column_name, periodicity, table):\n",
    "    # Create sin and cos encoding\n",
    "    table = table.with_columns(\n",
    "        sin_transformer(periodicity)\n",
    "        .fit_transform(table[column_name])\n",
    "        .alias(f\"{column_name}_sin\")\n",
    "    )\n",
    "\n",
    "    table = table.with_columns(\n",
    "        cos_transformer(periodicity)\n",
    "        .fit_transform(table[column_name])\n",
    "        .alias(f\"{column_name}_cos\")\n",
    "    )\n",
    "    # Drop the old column\n",
    "    table = table.drop(column_name)\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with column name and calendar periodicity\n",
    "calendar_features = {\n",
    "    \"day_of_month\": 31,\n",
    "    \"day_of_year\": 365,\n",
    "    \"day_of_week\": 7,\n",
    "    \"month\": 12,\n",
    "    \"hour\": 24,\n",
    "}\n",
    "\n",
    "for column_name, periodicity in calendar_features.items():\n",
    "    df = encode_cyclically(column_name, periodicity, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"holiday_name\"]\n",
    "\n",
    "num_cols = df.select(\n",
    "    cs.contains(\n",
    "        \"soil_temperature_7_to_28cm\",\n",
    "        \"shortwave_radiation\",\n",
    "    )\n",
    ").columns + [\"temp_rolling\"]\n",
    "\n",
    "manual_cols = df.select(pl.selectors.contains(\"_cos\", \"_sin\", \"is_\")).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(manual_cols + cat_cols + num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"encoder\",\n",
    "            OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_transformer, num_cols),\n",
    "        (\"categorical\", categorical_transformer, cat_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"column_transformer\", column_transformer),\n",
    "        (\n",
    "            \"variance_threshold\",\n",
    "            VarianceThreshold(threshold=0.0),\n",
    "        ),  # Drops constant columns after transformations\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelation Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = df.to_pandas()[\"kWh\"]\n",
    "acf_lags = 24 * 8\n",
    "\n",
    "acf_x = acf(time_series, nlags=acf_lags, alpha=0.05)\n",
    "\n",
    "acf_vals, acf_conf_int = acf_x[:2]\n",
    "\n",
    "acf_df = pd.DataFrame(\n",
    "    {\n",
    "        \"ACF\": acf_vals,\n",
    "        \"ACF_low\": acf_conf_int[:, 0],\n",
    "        \"ACF_high\": acf_conf_int[:, 1],\n",
    "        \"Lag\": np.arange(0, acf_lags + 1),\n",
    "    }\n",
    ")\n",
    "\n",
    "acf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_thr = 1.96 / np.sqrt(len(time_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_width = 7\n",
    "plot_height = 3\n",
    "\n",
    "fig = (\n",
    "    pn.ggplot(acf_df, pn.aes(x=\"Lag\", y=\"ACF\"))\n",
    "    + pn.geom_hline(yintercept=0, color=\"midnightblue\")\n",
    "    + pn.geom_segment(pn.aes(x=\"Lag\", xend=\"Lag\", y=0, yend=\"ACF\"), color=\"dodgerblue\")\n",
    "    + pn.geom_point(\n",
    "        color=\"dodgerblue\",\n",
    "    )\n",
    "    + pn.geom_hline(\n",
    "        yintercept=significance_thr, linetype=\"dotted\", color=\"midnightblue\"\n",
    "    )\n",
    "    + pn.geom_hline(\n",
    "        yintercept=-significance_thr, linetype=\"dotted\", color=\"midnightblue\"\n",
    "    )\n",
    "    + theme_academic\n",
    "    + pn.theme(figure_size=(plot_width, plot_height))\n",
    ")\n",
    "\n",
    "display(fig)\n",
    "\n",
    "fig.save(\n",
    "    filename=\"../1_figures/acf_differencing_0.pdf\",\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacf_x = pacf(time_series, nlags=acf_lags, alpha=0.05)\n",
    "\n",
    "pacf_vals, pacf_conf_int = pacf_x[:2]\n",
    "\n",
    "pacf_df = pd.DataFrame(\n",
    "    {\n",
    "        \"PACF\": pacf_vals,\n",
    "        \"PACF_low\": pacf_conf_int[:, 0],\n",
    "        \"PACF_high\": pacf_conf_int[:, 1],\n",
    "        \"Lag\": np.arange(0, acf_lags + 1),\n",
    "    }\n",
    ")\n",
    "\n",
    "pacf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_width = 7\n",
    "plot_height = 3\n",
    "\n",
    "fig = (\n",
    "    pn.ggplot(pacf_df, pn.aes(x=\"Lag\", y=\"PACF\"))\n",
    "    + pn.geom_hline(yintercept=0, color=\"midnightblue\")\n",
    "    + pn.geom_segment(pn.aes(x=\"Lag\", xend=\"Lag\", y=0, yend=\"PACF\"), color=\"dodgerblue\")\n",
    "    + pn.geom_point(\n",
    "        color=\"dodgerblue\",\n",
    "    )\n",
    "    + pn.geom_hline(\n",
    "        yintercept=significance_thr, linetype=\"dotted\", color=\"midnightblue\"\n",
    "    )\n",
    "    + pn.geom_hline(\n",
    "        yintercept=-significance_thr, linetype=\"dotted\", color=\"midnightblue\"\n",
    "    )\n",
    "    + theme_academic\n",
    "    + pn.theme(figure_size=(plot_width, plot_height))\n",
    ")\n",
    "\n",
    "display(fig)\n",
    "\n",
    "fig.save(\n",
    "    filename=\"../1_figures/pacf_differencing_0.pdf\",\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the ADF test\n",
    "adf_result = adfuller(time_series)\n",
    "\n",
    "# Display the results\n",
    "print(\"ADF Statistic:\", adf_result[0])\n",
    "print(\"p-value:\", adf_result[1])\n",
    "print(\"Critical Values:\")\n",
    "for key, value in adf_result[4].items():\n",
    "    print(f\"  {key}: {value:.3f}\")\n",
    "\n",
    "# Interpretation\n",
    "if adf_result[1] < 0.05:\n",
    "    print(\"The time series is likely stationary (reject the null hypothesis).\")\n",
    "else:\n",
    "    print(\n",
    "        \"The time series is likely non-stationary (fail to reject the null hypothesis).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpss_test(timeseries):\n",
    "    print(\"Results of KPSS Test:\")\n",
    "    kpsstest = kpss(timeseries, regression=\"c\", nlags=\"auto\")\n",
    "    kpss_output = pd.Series(\n",
    "        kpsstest[0:3], index=[\"Test Statistic\", \"p-value\", \"Lags Used\"]\n",
    "    )\n",
    "    for key, value in kpsstest[3].items():\n",
    "        kpss_output[\"Critical Value (%s)\" % key] = value\n",
    "    print(kpss_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpss_test(time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First order differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = df.to_pandas()[\"kWh\"]\n",
    "time_series = (time_series - time_series.shift(1)).dropna()\n",
    "\n",
    "acf_x = acf(time_series, nlags=acf_lags, alpha=0.05)\n",
    "\n",
    "acf_vals, acf_conf_int = acf_x[:2]\n",
    "\n",
    "acf_df = pd.DataFrame(\n",
    "    {\n",
    "        \"ACF\": acf_vals,\n",
    "        \"ACF_low\": acf_conf_int[:, 0],\n",
    "        \"ACF_high\": acf_conf_int[:, 1],\n",
    "        \"Lag\": np.arange(0, acf_lags + 1),\n",
    "    }\n",
    ")\n",
    "\n",
    "acf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_width = 7\n",
    "plot_height = 3\n",
    "\n",
    "fig = (\n",
    "    pn.ggplot(acf_df, pn.aes(x=\"Lag\", y=\"ACF\"))\n",
    "    + pn.geom_hline(yintercept=0, color=\"midnightblue\")\n",
    "    + pn.geom_segment(pn.aes(x=\"Lag\", xend=\"Lag\", y=0, yend=\"ACF\"), color=\"dodgerblue\")\n",
    "    + pn.geom_point(\n",
    "        color=\"dodgerblue\",\n",
    "    )\n",
    "    + pn.geom_hline(\n",
    "        yintercept=significance_thr, linetype=\"dotted\", color=\"midnightblue\"\n",
    "    )\n",
    "    + pn.geom_hline(\n",
    "        yintercept=-significance_thr, linetype=\"dotted\", color=\"midnightblue\"\n",
    "    )\n",
    "    + theme_academic\n",
    "    + pn.theme(figure_size=(plot_width, plot_height))\n",
    ")\n",
    "\n",
    "display(fig)\n",
    "\n",
    "fig.save(\n",
    "    filename=\"../1_figures/acf_differencing_1.pdf\",\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacf_x = pacf(time_series, nlags=acf_lags, alpha=0.05)\n",
    "\n",
    "pacf_vals, pacf_conf_int = pacf_x[:2]\n",
    "\n",
    "pacf_df = pd.DataFrame(\n",
    "    {\n",
    "        \"PACF\": pacf_vals,\n",
    "        \"PACF_low\": pacf_conf_int[:, 0],\n",
    "        \"PACF_high\": pacf_conf_int[:, 1],\n",
    "        \"Lag\": np.arange(0, acf_lags + 1),\n",
    "    }\n",
    ")\n",
    "\n",
    "pacf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_width = 7\n",
    "plot_height = 3\n",
    "\n",
    "fig = (\n",
    "    pn.ggplot(pacf_df, pn.aes(x=\"Lag\", y=\"PACF\"))\n",
    "    + pn.geom_hline(yintercept=0, color=\"midnightblue\")\n",
    "    + pn.geom_segment(pn.aes(x=\"Lag\", xend=\"Lag\", y=0, yend=\"PACF\"), color=\"dodgerblue\")\n",
    "    + pn.geom_point(\n",
    "        color=\"dodgerblue\",\n",
    "    )\n",
    "    + pn.geom_hline(\n",
    "        yintercept=significance_thr, linetype=\"dotted\", color=\"midnightblue\"\n",
    "    )\n",
    "    + pn.geom_hline(\n",
    "        yintercept=-significance_thr, linetype=\"dotted\", color=\"midnightblue\"\n",
    "    )\n",
    "    + theme_academic\n",
    "    + pn.theme(figure_size=(plot_width, plot_height))\n",
    ")\n",
    "\n",
    "display(fig)\n",
    "\n",
    "fig.save(\n",
    "    filename=\"../1_figures/pacf_differencing_1.pdf\",\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the ADF test\n",
    "adf_result = adfuller(time_series)\n",
    "\n",
    "# Display the results\n",
    "print(\"ADF Statistic:\", adf_result[0])\n",
    "print(\"p-value:\", adf_result[1])\n",
    "print(\"Critical Values:\")\n",
    "for key, value in adf_result[4].items():\n",
    "    print(f\"  {key}: {value:.3f}\")\n",
    "\n",
    "# Interpretation\n",
    "if adf_result[1] < 0.05:\n",
    "    print(\"The time series is likely stationary (reject the null hypothesis).\")\n",
    "else:\n",
    "    print(\n",
    "        \"The time series is likely non-stationary (fail to reject the null hypothesis).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpss_test(time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Selection (Parameter Tuning) with `statsforecast`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational complexity extrapolation chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = (\n",
    "    df.to_pandas()\n",
    "    .assign(datetime=lambda x: x.datetime.astype(\"datetime64[ns]\"))\n",
    "    .set_index(\"datetime\")\n",
    "    .asfreq(\"h\")\n",
    "    .sort_index()\n",
    ")\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go a lot smaller on the data to make computation feasible\n",
    "df_train = df_full[\"2023-06-01\":\"2023-06-30\"]\n",
    "df_val = df_full[\"2023-07-01\":\"2023-07-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"kWh\"])\n",
    "X_val = df_val.drop(columns=[\"kWh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pd.DataFrame(\n",
    "    preprocessor.fit_transform(X_train),\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    ")\n",
    "\n",
    "X_val_preprocessed = pd.DataFrame(\n",
    "    preprocessor.transform(X_val),\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    ")\n",
    "\n",
    "y_train = df_train[\"kWh\"]\n",
    "y_val = df_val[\"kWh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = X_train_preprocessed.apply(pd.to_numeric, errors=\"coerce\")\n",
    "X_val_preprocessed = X_val_preprocessed.apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs_list = np.arange(200, 700 + 1, 100)\n",
    "fit_times = []\n",
    "\n",
    "for n_obs in tqdm(n_obs_list):\n",
    "\n",
    "    model = ARIMA(\n",
    "        order=(1, 1, 1),\n",
    "        season_length=24,\n",
    "        seasonal_order=(1, 1, 1),\n",
    "        # include_drift=True\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(\n",
    "        y=y_train.head(n_obs).to_numpy(dtype=np.float64),\n",
    "        X=X_train_preprocessed.head(n_obs).to_numpy(dtype=np.float64),\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    fit_times.append((end_time - start_time) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(\n",
    "        data=pd.DataFrame({\"n\": n_obs_list, \"fit_time\": fit_times}),\n",
    "        mapping=pn.aes(\"n\", \"fit_time\"),\n",
    "    )\n",
    "    + pn.geom_line()\n",
    "    + pn.geom_point()\n",
    "    + pn.labs(\n",
    "        title=\"SARIMAX fit times depending on number of observations\",\n",
    "        subtitle=\"SARIMAX(1,1,1)(1,1,1)(24)\",\n",
    "        x=\"# observations\",\n",
    "        y=\"Fit Time (minutes)\",\n",
    "    )\n",
    "    + pn.geom_smooth(method=\"lm\", colour=\"blue\", size=0.25)\n",
    "    + theme_academic\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrapolation linearly: SARIMAX on hourly data with this configuration will take (minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0] / n_obs_list[-1] * fit_times[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Fitting a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, X_train, X_val, y_train, y_val, verbose=True):\n",
    "    # Validation loop (predict the next 24 hours for the validation period)\n",
    "    X_train_val = pd.concat([X_train, X_val], axis=0)\n",
    "    y_train_val = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "    # To prevent function becoming slow due to linearly growing history\n",
    "    max_history_obs = 168 * 2\n",
    "\n",
    "    val_index = X_train.shape[0]\n",
    "    horizon = 24\n",
    "    val_preds = np.array([])\n",
    "\n",
    "    while val_index + horizon <= X_train_val.shape[0]:\n",
    "\n",
    "        y_pred = model.forward(\n",
    "            y=y_train_val[\n",
    "                np.amax([0, val_index - max_history_obs]) : val_index\n",
    "            ].to_numpy(dtype=np.float64),\n",
    "            h=24,\n",
    "            X=X_train_val[\n",
    "                np.amax([0, val_index - max_history_obs]) : val_index\n",
    "            ].to_numpy(dtype=np.float64),\n",
    "            X_future=X_train_val[val_index : val_index + horizon].to_numpy(\n",
    "                dtype=np.float64\n",
    "            ),\n",
    "        )[\"mean\"]\n",
    "\n",
    "        # Append to array\n",
    "        val_preds = np.append(val_preds, y_pred)\n",
    "\n",
    "        # Increment validation index\n",
    "        val_index += horizon\n",
    "\n",
    "        if (val_position := val_index - X_train.shape[0]) % 24 == 0 and verbose:\n",
    "            print(f\"Hour {val_position} of {X_val.shape[0]}\")\n",
    "            clear_output(wait=True)\n",
    "\n",
    "    return np.vstack(val_preds).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = (\n",
    "    df.to_pandas()\n",
    "    .assign(\n",
    "        datetime=lambda x: x.datetime.astype(\"datetime64[ns]\"),\n",
    "    )\n",
    "    .set_index(\"datetime\")\n",
    "    .asfreq(\"h\")\n",
    "    .sort_index()\n",
    ")\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go a lot smaller on the data to make computation feasible\n",
    "df_train = df_full[\"2023-06-01\":\"2023-06-30\"]\n",
    "df_val = df_full[\"2023-07-01\":\"2023-07-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"kWh\"])\n",
    "X_val = df_val.drop(columns=[\"kWh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pd.DataFrame(\n",
    "    preprocessor.fit_transform(X_train),\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    ")\n",
    "\n",
    "X_val_preprocessed = pd.DataFrame(\n",
    "    preprocessor.transform(X_val),\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    ")\n",
    "\n",
    "y_train = df_train[\"kWh\"]\n",
    "y_val = df_val[\"kWh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(\n",
    "    order=(1, 1, 1),\n",
    "    season_length=168,\n",
    "    seasonal_order=(1, 1, 1),\n",
    "    # include_drift=True\n",
    ")\n",
    "\n",
    "model = model.fit(\n",
    "    y=y_train.to_numpy(dtype=np.float64),\n",
    "    X=X_train_preprocessed.to_numpy(dtype=np.float64),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the setup to predict one day into the future\n",
    "# without refitting the model\n",
    "\n",
    "y_preds = model.forward(\n",
    "    y=y_train.to_numpy(dtype=np.float64),\n",
    "    h=24,\n",
    "    X=X_train_preprocessed.to_numpy(dtype=np.float64),\n",
    "    X_future=X_val_preprocessed.head(24).to_numpy(dtype=np.float64),\n",
    ")[\"mean\"]\n",
    "\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = validation(\n",
    "    model=model,\n",
    "    X_train=X_train_preprocessed,\n",
    "    X_val=X_val_preprocessed,\n",
    "    y_train=y_train,\n",
    "    y_val=y_val,\n",
    ")\n",
    "\n",
    "\n",
    "preds_168 = pd.DataFrame(\n",
    "    {\n",
    "        \"pred\": y_pred,\n",
    "        \"kWh\": y_val,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure with step lines for both actual and predicted values\n",
    "fig = px.line(\n",
    "    preds_168.reset_index(),\n",
    "    x=\"datetime\",\n",
    "    y=[\"kWh\", \"pred\"],\n",
    "    labels={\n",
    "        \"datetime\": \"Date\",\n",
    "        \"value\": \"Energy Consumption (kWh)\",\n",
    "        \"variable\": \"Series\",\n",
    "    },\n",
    "    title=\"Actual vs Predicted Energy Consumption Over Time\",\n",
    "    line_shape=\"hv\",  # Set line shape to horizontal-vertical for step chart\n",
    ")\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(title=\"\"),\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Energy Consumption (kWh)\",\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(\n",
    "    order=(1, 1, 1),\n",
    "    season_length=24,\n",
    "    seasonal_order=(1, 1, 1),\n",
    "    # include_drift=True\n",
    ")\n",
    "\n",
    "model = model.fit(\n",
    "    y=y_train.to_numpy(dtype=np.float64),\n",
    "    X=X_train_preprocessed.to_numpy(dtype=np.float64),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = validation(\n",
    "    model=model,\n",
    "    X_train=X_train_preprocessed,\n",
    "    X_val=X_val_preprocessed,\n",
    "    y_train=y_train,\n",
    "    y_val=y_val,\n",
    ")\n",
    "\n",
    "\n",
    "preds_24 = pd.DataFrame(\n",
    "    {\n",
    "        \"pred\": y_pred,\n",
    "        \"kWh\": y_val,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure with step lines for both actual and predicted values\n",
    "fig = px.line(\n",
    "    preds_24.reset_index(),\n",
    "    x=\"datetime\",\n",
    "    y=[\"kWh\", \"pred\"],\n",
    "    labels={\n",
    "        \"datetime\": \"Date\",\n",
    "        \"value\": \"Energy Consumption (kWh)\",\n",
    "        \"variable\": \"Series\",\n",
    "    },\n",
    "    title=\"Actual vs Predicted Energy Consumption Over Time\",\n",
    "    line_shape=\"hv\",  # Set line shape to horizontal-vertical for step chart\n",
    ")\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(title=\"\"),\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Energy Consumption (kWh)\",\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        preds_168.assign(seasonality=168).reset_index(),\n",
    "        preds_24.assign(seasonality=24).reset_index(),\n",
    "    ],\n",
    "    axis=0,\n",
    ").to_csv(\"3_SARIMAX_seasonality_24_168_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_width = 7\n",
    "plot_height = 3\n",
    "\n",
    "fig = (\n",
    "    pn.ggplot(\n",
    "        data=(\n",
    "            pd.read_csv(\n",
    "                \"3_SARIMAX_seasonality_24_168_comparison.csv\", parse_dates=[\"datetime\"]\n",
    "            )\n",
    "            .melt(id_vars=[\"datetime\", \"seasonality\"])\n",
    "            .assign(\n",
    "                seasonality=lambda x: pd.Categorical(\n",
    "                    np.where(x[\"seasonality\"] == 168, \"s=168\", \"s=24\"),\n",
    "                    categories=[\"s=24\", \"s=168\"],\n",
    "                    ordered=True,\n",
    "                ),\n",
    "                variable=lambda x: np.where(\n",
    "                    x[\"variable\"] == \"pred\", \"Prediction\", \"Actual\"\n",
    "                ),\n",
    "            )\n",
    "        ),\n",
    "        mapping=pn.aes(\"datetime\", \"value\", colour=\"variable\"),\n",
    "    )\n",
    "    + pn.geom_step()\n",
    "    + pn.labs(y=\"kWh\")\n",
    "    + pn.facet_wrap(\"~ seasonality\", ncol=1)\n",
    "    + pn.scale_colour_manual(values=jama_colour)\n",
    "    + pn.scale_x_datetime(date_breaks=\"1 week\")\n",
    "    + pn.scale_y_continuous(labels=comma_format())\n",
    "    + theme_academic\n",
    "    + pn.theme(\n",
    "        figure_size=(plot_width, plot_height),\n",
    "        axis_title_x=pn.element_blank(),\n",
    "        legend_title=pn.element_blank(),\n",
    "    )\n",
    ")\n",
    "\n",
    "display(fig)\n",
    "fig.save(\n",
    "    filename=\"../1_figures/sarimax_seasonality_24_vs_168.pdf\",\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoARIMA\n",
    "\n",
    "Use information criterion to select the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = (\n",
    "    df.to_pandas()\n",
    "    .assign(datetime=lambda x: x.datetime.astype(\"datetime64[ns]\"))\n",
    "    .set_index(\"datetime\")\n",
    "    .asfreq(\"h\")\n",
    "    .sort_index()\n",
    ")\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_full[:\"2023-08-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"kWh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pd.DataFrame(\n",
    "    preprocessor.fit_transform(X_train),\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    ")\n",
    "\n",
    "y_train = df_train[\"kWh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model = AutoARIMA(\n",
    "    d=1,\n",
    "    D=1,\n",
    "    max_p=24,\n",
    "    max_q=24,\n",
    "    max_P=1,\n",
    "    max_Q=1,\n",
    "    stepwise=True,\n",
    "    approximation=True,\n",
    "    trace=True,\n",
    "    season_length=168,\n",
    ")\n",
    "\n",
    "model = model.fit(\n",
    "    y=y_train.to_numpy(dtype=np.float64),\n",
    "    X=X_train_preprocessed.to_numpy(dtype=np.float64),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model object\n",
    "with open(\"autoarima_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model.model_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Validation for Order Selection\n",
    "\n",
    "Repeat the same as manual fit (train/val split), but do order selection via fitting all order and selecting the best one (for p,q,P,Q) separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = (\n",
    "    df.to_pandas()\n",
    "    .assign(datetime=lambda x: x.datetime.astype(\"datetime64[ns]\"))\n",
    "    .set_index(\"datetime\")\n",
    "    .asfreq(\"h\")\n",
    "    .sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go a lot smaller on the data to make computation feasible\n",
    "df_train = df_full[\"2023-06-01\":\"2023-06-30\"]\n",
    "df_val = df_full[\"2023-07-01\":\"2023-07-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"kWh\"])\n",
    "X_val = df_val.drop(columns=[\"kWh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pd.DataFrame(\n",
    "    preprocessor.fit_transform(X_train),\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    ")\n",
    "\n",
    "X_val_preprocessed = pd.DataFrame(\n",
    "    preprocessor.transform(X_val),\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    ")\n",
    "\n",
    "y_train = df_train[\"kWh\"]\n",
    "y_val = df_val[\"kWh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_search_space = np.arange(0, 24 + 1)\n",
    "q_search_space = np.arange(0, 24 + 1)\n",
    "P_search_space = np.arange(0, 1 + 1)\n",
    "Q_search_space = np.arange(0, 1 + 1)\n",
    "\n",
    "param_search_spaces = {\n",
    "    \"p\": p_search_space,\n",
    "    \"q\": q_search_space,\n",
    "    \"P\": P_search_space,\n",
    "    \"Q\": Q_search_space,\n",
    "}\n",
    "\n",
    "y_preds_val = []\n",
    "\n",
    "for param, search_space in param_search_spaces.items():\n",
    "\n",
    "    for param_value in tqdm(search_space):\n",
    "\n",
    "        current_model_config = {\"p\": 0, \"q\": 0, \"P\": 0, \"Q\": 0}\n",
    "        current_model_config[param] = int(param_value)\n",
    "\n",
    "        model = ARIMA(\n",
    "            order=(current_model_config[\"p\"], 1, current_model_config[\"q\"]),\n",
    "            season_length=168,\n",
    "            seasonal_order=(current_model_config[\"P\"], 1, current_model_config[\"Q\"]),\n",
    "        )\n",
    "\n",
    "        # Fit the model on the training data\n",
    "        model = model.fit(\n",
    "            y=y_train.to_numpy(dtype=np.float64),\n",
    "            X=X_train_preprocessed.to_numpy(dtype=np.float64),\n",
    "        )\n",
    "\n",
    "        # Validate the model performance\n",
    "        y_pred = validation(\n",
    "            model=model,\n",
    "            X_train=X_train_preprocessed,\n",
    "            X_val=X_val_preprocessed,\n",
    "            y_train=y_train,\n",
    "            y_val=y_val,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        y_pred = pd.DataFrame(\n",
    "            {\n",
    "                \"pred\": y_pred,\n",
    "                \"kWh\": y_val,\n",
    "            }\n",
    "        ).assign(\n",
    "            p=current_model_config[\"p\"],\n",
    "            q=current_model_config[\"q\"],\n",
    "            P=current_model_config[\"P\"],\n",
    "            Q=current_model_config[\"Q\"],\n",
    "        )\n",
    "\n",
    "        y_preds_val.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(y_preds_val).to_csv(\"3_SARIMAX_manual_order_selection.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_width = 7\n",
    "plot_height = 3\n",
    "\n",
    "fig = (\n",
    "    pn.ggplot(\n",
    "        data=(\n",
    "            pl.read_csv(\"3_SARIMAX_manual_order_selection.csv\")\n",
    "            .group_by([\"p\", \"q\", \"P\", \"Q\"])\n",
    "            .agg(loss=(pl.col(\"pred\") - pl.col(\"kWh\")).pow(2).mean().sqrt())\n",
    "            .unpivot(index=\"loss\")\n",
    "            .filter(pl.col(\"value\") > 0)\n",
    "            .filter(pl.col(\"variable\").is_in([\"p\", \"q\"]))\n",
    "        ),\n",
    "        mapping=pn.aes(\"value\", \"loss\"),\n",
    "    )\n",
    "    + pn.geom_point()\n",
    "    + pn.facet_wrap(\"~ variable\")\n",
    "    + pn.labs(y=\"RMSE\", x=\"Order\")\n",
    "    + pn.scale_y_continuous(labels=comma_format())\n",
    "    + theme_academic\n",
    "    + pn.theme(figure_size=(plot_width, plot_height), legend_position=\"bottom\")\n",
    ")\n",
    "\n",
    "display(fig)\n",
    "fig.save(\n",
    "    filename=\"../1_figures/order_selection_manual_p_and_q.pdf\",\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RayTune Tuning Setup\n",
    "\n",
    "Repeat the same as manual fit (train/val split), but do order selection via OptunaSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = (\n",
    "    df.to_pandas()\n",
    "    .assign(datetime=lambda x: x.datetime.astype(\"datetime64[ns]\"))\n",
    "    .set_index(\"datetime\")\n",
    "    .asfreq(\"h\")\n",
    "    .sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go a lot smaller on the data to make computation feasible\n",
    "df_train = df_full[\"2023-06-01\":\"2023-06-30\"]\n",
    "df_val = df_full[\"2023-07-01\":\"2023-07-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"kWh\"])\n",
    "X_val = df_val.drop(columns=[\"kWh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pd.DataFrame(\n",
    "    preprocessor.fit_transform(X_train),\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    ")\n",
    "\n",
    "X_val_preprocessed = pd.DataFrame(\n",
    "    preprocessor.transform(X_val),\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    ")\n",
    "\n",
    "y_train = df_train[\"kWh\"]\n",
    "y_val = df_val[\"kWh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarimax_trainable(config, df_train, df_val):\n",
    "\n",
    "    try:\n",
    "        # Initialize the ARIMA model with the given configuration\n",
    "        model = ARIMA(\n",
    "            order=(config[\"p\"], config[\"d\"], config[\"q\"]),\n",
    "            season_length=168,\n",
    "            seasonal_order=(config[\"P\"], config[\"D\"], config[\"Q\"]),\n",
    "        )\n",
    "\n",
    "        # Fit the model on the training data\n",
    "        model = model.fit(\n",
    "            y=y_train.to_numpy(dtype=np.float64),\n",
    "            X=X_train_preprocessed.to_numpy(dtype=np.float64),\n",
    "        )\n",
    "\n",
    "        y_pred = validation(\n",
    "            model=model,\n",
    "            X_train=X_train_preprocessed,\n",
    "            X_val=X_val_preprocessed,\n",
    "            y_train=y_train,\n",
    "            y_val=y_val,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        y_preds_val = pd.DataFrame(\n",
    "            {\n",
    "                \"pred\": y_pred,\n",
    "                \"kWh\": y_val,\n",
    "            }\n",
    "        )\n",
    "        loss = root_mean_squared_error(\n",
    "            y_pred=y_preds_val[\"pred\"], y_true=y_preds_val[\"kWh\"]\n",
    "        )\n",
    "        train.report({\"loss\": loss})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")  # Print error message for debugging\n",
    "        train.report({\"loss\": float(\"inf\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this line for locally defined modules to work with ray\n",
    "# ray.init(runtime_env={\"working_dir\": \".\"}, ignore_reinit_error=True)\n",
    "np.random.seed(42)\n",
    "\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(sarimax_trainable, df_train=df_train, df_val=df_val),\n",
    "    config={\n",
    "        \"p\": tune.randint(0, 24 + 1),\n",
    "        \"q\": tune.randint(0, 24 + 1),\n",
    "        \"P\": tune.randint(0, 1 + 1),\n",
    "        \"Q\": tune.randint(0, 1 + 1),\n",
    "        \"d\": 1,\n",
    "        \"D\": 1,\n",
    "    },\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    name=\"SARIMAX\",\n",
    "    search_alg=OptunaSearch(),\n",
    "    time_budget_s=60 * 60 * 6,\n",
    "    num_samples=-1,\n",
    "    max_concurrent_trials=8,\n",
    "    raise_on_failed_trial=False,\n",
    "    trial_dirname_creator=lambda trial: f\"{trial.trainable_name}_{trial.trial_id}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.dataframe().to_csv(\"3_SARIMAX_trials.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Performance of the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df = pl.read_csv(\"3_SARIMAX_trials.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(\n",
    "        data=(trials_df.with_columns(total_minutes=pl.col(\"time_total_s\") / 60)),\n",
    "        mapping=pn.aes(\"total_minutes\"),\n",
    "    )\n",
    "    + pn.geom_histogram(bins=50)\n",
    "    + theme_academic\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams_df = (\n",
    "    pl.read_csv(\"3_SARIMAX_trials.csv\")\n",
    "    .sort(\"loss\")\n",
    "    .head(1)\n",
    "    .select(pl.selectors.contains(\"config/\"))\n",
    "    .unpivot()\n",
    "    .with_columns(\n",
    "        pl.col(\"variable\").str.replace(\"config/\", \"\"), pl.col(\"value\").cast(pl.Int64)\n",
    "    )\n",
    ")\n",
    "\n",
    "best_hyperparams = dict(\n",
    "    zip(best_hyperparams_df[\"variable\"], best_hyperparams_df[\"value\"])\n",
    ")\n",
    "\n",
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(\n",
    "    order=(\n",
    "        best_hyperparams[\"p\"],\n",
    "        best_hyperparams[\"d\"],\n",
    "        best_hyperparams[\"q\"],\n",
    "    ),\n",
    "    season_length=168,\n",
    "    seasonal_order=(\n",
    "        best_hyperparams[\"P\"],\n",
    "        best_hyperparams[\"D\"],\n",
    "        best_hyperparams[\"Q\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit the model on the full data\n",
    "model = model.fit(\n",
    "    y=y_train.to_numpy(dtype=np.float64),\n",
    "    X=X_train_preprocessed.to_numpy(dtype=np.float64),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = validation(\n",
    "    model=model,\n",
    "    X_train=X_train_preprocessed,\n",
    "    X_val=X_val_preprocessed,\n",
    "    y_train=y_train,\n",
    "    y_val=y_val,\n",
    ")\n",
    "\n",
    "y_preds_val = pd.DataFrame(\n",
    "    {\n",
    "        \"pred\": y_pred,\n",
    "        \"kWh\": y_val,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = root_mean_squared_error(y_pred=y_preds_val[\"pred\"], y_true=y_preds_val[\"kWh\"])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure with step lines for both actual and predicted values\n",
    "fig = px.line(\n",
    "    y_preds_val.reset_index(),\n",
    "    x=\"datetime\",\n",
    "    y=[\"kWh\", \"pred\"],\n",
    "    labels={\n",
    "        \"datetime\": \"Date\",\n",
    "        \"value\": \"Energy Consumption (kWh)\",\n",
    "        \"variable\": \"Series\",\n",
    "    },\n",
    "    title=\"Actual vs Predicted Energy Consumption Over Time\",\n",
    "    line_shape=\"hv\",  # Set line shape to horizontal-vertical for step chart\n",
    ")\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(title=\"\"),\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Energy Consumption (kWh)\",\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"autoarima_model.pkl\", \"rb\") as f:\n",
    "    model_summary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams_autoarima = {\n",
    "    \"p\": sum(1 for key in model_summary[\"coef\"] if key.startswith(\"ar\")),\n",
    "    \"q\": sum(1 for key in model_summary[\"coef\"] if key.startswith(\"ma\")),\n",
    "    \"P\": sum(1 for key in model_summary[\"coef\"] if key.startswith(\"sar\")),\n",
    "    \"Q\": sum(1 for key in model_summary[\"coef\"] if key.startswith(\"sma\")),\n",
    "    \"d\": 1,\n",
    "    \"D\": 1,\n",
    "}\n",
    "\n",
    "best_hyperparams_autoarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(\n",
    "    order=(\n",
    "        best_hyperparams_autoarima[\"p\"],\n",
    "        best_hyperparams_autoarima[\"d\"],\n",
    "        best_hyperparams_autoarima[\"q\"],\n",
    "    ),\n",
    "    season_length=168,\n",
    "    seasonal_order=(\n",
    "        best_hyperparams_autoarima[\"P\"],\n",
    "        best_hyperparams_autoarima[\"D\"],\n",
    "        best_hyperparams_autoarima[\"Q\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fit the model on the full data\n",
    "model = model.fit(\n",
    "    y=y_train.to_numpy(dtype=np.float64),\n",
    "    X=X_train_preprocessed.to_numpy(dtype=np.float64),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = validation(\n",
    "    model=model,\n",
    "    X_train=X_train_preprocessed,\n",
    "    X_val=X_val_preprocessed,\n",
    "    y_train=y_train,\n",
    "    y_val=y_val,\n",
    ")\n",
    "\n",
    "y_preds_val = pd.DataFrame(\n",
    "    {\n",
    "        \"pred\": y_pred,\n",
    "        \"kWh\": y_val,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = root_mean_squared_error(y_pred=y_preds_val[\"pred\"], y_true=y_preds_val[\"kWh\"])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure with step lines for both actual and predicted values\n",
    "fig = px.line(\n",
    "    y_preds_val.reset_index(),\n",
    "    x=\"datetime\",\n",
    "    y=[\"kWh\", \"pred\"],\n",
    "    labels={\n",
    "        \"datetime\": \"Date\",\n",
    "        \"value\": \"Energy Consumption (kWh)\",\n",
    "        \"variable\": \"Series\",\n",
    "    },\n",
    "    title=\"Actual vs Predicted Energy Consumption Over Time\",\n",
    "    line_shape=\"hv\",  # Set line shape to horizontal-vertical for step chart\n",
    ")\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(title=\"\"),\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Energy Consumption (kWh)\",\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Evaluation without Retraining\n",
    "\n",
    "- fit the model once on the trainval set\n",
    "- evaluate over the entire year and store predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams_df = (\n",
    "    pl.read_csv(\"3_SARIMAX_trials.csv\")\n",
    "    .sort(\"loss\")\n",
    "    .head(1)\n",
    "    .select(pl.selectors.contains(\"config/\"))\n",
    "    .unpivot()\n",
    "    .with_columns(\n",
    "        pl.col(\"variable\").str.replace(\"config/\", \"\"), pl.col(\"value\").cast(pl.Int64)\n",
    "    )\n",
    ")\n",
    "\n",
    "best_hyperparams = dict(\n",
    "    zip(best_hyperparams_df[\"variable\"], best_hyperparams_df[\"value\"])\n",
    ")\n",
    "\n",
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trainval = df_full[\"2022-09-01\":\"2023-08-31\"]\n",
    "df_holdout = df_full[\"2023-09-01\":\"2024-08-31\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval = df_trainval.drop(columns=[\"kWh\"])\n",
    "X_holdout = df_holdout.drop(columns=[\"kWh\"])\n",
    "\n",
    "X_trainval_preprocessed = pd.DataFrame(\n",
    "    preprocessor.fit_transform(X_trainval),\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    ")\n",
    "\n",
    "X_holdout_preprocessed = pd.DataFrame(\n",
    "    preprocessor.transform(X_holdout),\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainval = df_trainval[\"kWh\"]\n",
    "y_holdout = df_holdout[\"kWh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model on the training and validation period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model with best hyperparameters on history\n",
    "model = ARIMA(\n",
    "    order=(\n",
    "        best_hyperparams[\"p\"],\n",
    "        best_hyperparams[\"d\"],\n",
    "        best_hyperparams[\"q\"],\n",
    "    ),\n",
    "    season_length=168,\n",
    "    seasonal_order=(\n",
    "        best_hyperparams[\"P\"],\n",
    "        best_hyperparams[\"D\"],\n",
    "        best_hyperparams[\"Q\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "model = model.fit(\n",
    "    y=y_trainval.to_numpy(dtype=np.float64),\n",
    "    X=X_trainval_preprocessed.to_numpy(dtype=np.float64),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = validation(\n",
    "    model=model,\n",
    "    X_train=X_trainval_preprocessed,\n",
    "    X_val=X_holdout_preprocessed,\n",
    "    y_train=y_trainval,\n",
    "    y_val=y_holdout,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_holdout = pd.DataFrame(\n",
    "    {\n",
    "        \"pred\": y_pred,\n",
    "        \"kWh\": y_holdout,\n",
    "    }\n",
    ")\n",
    "\n",
    "y_preds_holdout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.DataFrame(data=model.model_[\"coef\"]).to_pandas().to_csv(\n",
    "    \"3_SARIMAX_holdout_model_coefficients.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    y_preds_holdout.reset_index().to_csv(\n",
    "        \"3_SARIMAX_holdout_predictions_no_retraining.csv\", index=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure with step lines for both actual and predicted values\n",
    "fig = px.line(\n",
    "    y_preds_holdout.reset_index(),\n",
    "    x=\"datetime\",\n",
    "    y=[\"kWh\", \"pred\"],\n",
    "    labels={\n",
    "        \"datetime\": \"Date\",\n",
    "        \"value\": \"Energy Consumption (kWh)\",\n",
    "        \"variable\": \"Series\",\n",
    "    },\n",
    "    title=\"Actual vs Predicted Energy Consumption Over Time\",\n",
    "    line_shape=\"hv\",  # Set line shape to horizontal-vertical for step chart\n",
    ")\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(title=\"\"),\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Energy Consumption (kWh)\",\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Evaluation with Retraining\n",
    "\n",
    "Retrain weekly, then predict the entire following week without retraining.\n",
    "\n",
    "- Training Size: Can not be much longer than a month, so go with that for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_hyperparams_df = (\n",
    "#     pl.read_csv(\"3_SARIMAX_trials.csv\")\n",
    "#     .sort(\"loss\")\n",
    "#     .head(1)\n",
    "#     .select(pl.selectors.contains(\"config/\"))\n",
    "#     .unpivot()\n",
    "#     .with_columns(\n",
    "#         pl.col(\"variable\").str.replace(\"config/\", \"\"), pl.col(\"value\").cast(pl.Int64)\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# best_hyperparams = dict(\n",
    "#     zip(best_hyperparams_df[\"variable\"], best_hyperparams_df[\"value\"])\n",
    "# )\n",
    "\n",
    "# best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"autoarima_model.pkl\", \"rb\") as f:\n",
    "#     model_summary = pickle.load(f)\n",
    "\n",
    "# best_hyperparams_autoarima = {\n",
    "#     \"p\": sum(1 for key in model_summary[\"coef\"] if key.startswith(\"ar\")),\n",
    "#     \"q\": sum(1 for key in model_summary[\"coef\"] if key.startswith(\"ma\")),\n",
    "#     \"P\": sum(1 for key in model_summary[\"coef\"] if key.startswith(\"sar\")),\n",
    "#     \"Q\": sum(1 for key in model_summary[\"coef\"] if key.startswith(\"sma\")),\n",
    "#     \"d\": 1,\n",
    "#     \"D\": 1,\n",
    "# }\n",
    "\n",
    "# best_hyperparams_autoarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_trainval = df_full[\"2022-09-01\":\"2023-08-31\"]\n",
    "# df_holdout = df_full[\"2023-09-01\":\"2024-08-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retraining_freq = 7 * 24\n",
    "# retraining_indices = np.arange(0, df_holdout.shape[0], retraining_freq).tolist()\n",
    "# y_preds_list = []\n",
    "# model_coefs_list = []\n",
    "\n",
    "# for holdout_index in tqdm(retraining_indices):\n",
    "\n",
    "#     # Preprocess training history df\n",
    "#     X_train = pd.concat(\n",
    "#         [\n",
    "#             df_trainval.iloc[holdout_index:].drop(columns=[\"kWh\"]),\n",
    "#             df_holdout.iloc[:holdout_index].drop(columns=[\"kWh\"]),\n",
    "#         ],\n",
    "#         axis=0,\n",
    "#     )\n",
    "#     X_train_preprocessed = pd.DataFrame(\n",
    "#         preprocessor.fit_transform(X_train),\n",
    "#         columns=preprocessor.get_feature_names_out(),\n",
    "#     )\n",
    "\n",
    "#     X_holdout = df_holdout.iloc[holdout_index : holdout_index + retraining_freq].drop(\n",
    "#         columns=[\"kWh\"]\n",
    "#     )\n",
    "#     X_holdout_preprocessed = pd.DataFrame(\n",
    "#         preprocessor.transform(X_holdout),\n",
    "#         columns=preprocessor.get_feature_names_out(),\n",
    "#     )\n",
    "\n",
    "#     y_train = pd.concat(\n",
    "#         [\n",
    "#             df_trainval.iloc[holdout_index:][\"kWh\"],\n",
    "#             df_holdout.iloc[:holdout_index][\"kWh\"],\n",
    "#         ],\n",
    "#         axis=0,\n",
    "#     )\n",
    "#     y_holdout = df_holdout.iloc[holdout_index : holdout_index + retraining_freq][\"kWh\"]\n",
    "\n",
    "#     # Fit model with best hyperparameters on history\n",
    "#     model = ARIMA(\n",
    "#         order=(\n",
    "#             best_hyperparams[\"p\"],\n",
    "#             best_hyperparams[\"d\"],\n",
    "#             best_hyperparams[\"q\"],\n",
    "#         ),\n",
    "#         season_length=168,\n",
    "#         seasonal_order=(\n",
    "#             best_hyperparams[\"P\"],\n",
    "#             best_hyperparams[\"D\"],\n",
    "#             best_hyperparams[\"Q\"],\n",
    "#         ),\n",
    "#     )\n",
    "\n",
    "#     model = model.fit(\n",
    "#         y=y_train.to_numpy(dtype=np.float64),\n",
    "#         X=X_train_preprocessed.to_numpy(dtype=np.float64),\n",
    "#     )\n",
    "\n",
    "#     # Save the model coefficients for later visualisation\n",
    "#     model_coefs_list.append(pl.DataFrame(data=model.model_[\"coef\"]))\n",
    "\n",
    "#     # Make predictions for that week and store them\n",
    "#     y_pred = validation(\n",
    "#         model=model,\n",
    "#         X_train=X_train_preprocessed,\n",
    "#         X_val=X_holdout_preprocessed,\n",
    "#         y_train=y_train,\n",
    "#         y_val=y_holdout,\n",
    "#         verbose=False,\n",
    "#     )\n",
    "\n",
    "#     y_preds_list.append(\n",
    "#         pd.DataFrame(\n",
    "#             {\n",
    "#                 \"pred\": y_pred,\n",
    "#                 \"kWh\": y_holdout,\n",
    "#             }\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     # Increment holdout index\n",
    "#     holdout_index += retraining_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     pd.concat(y_preds_list)\n",
    "#     .reset_index()\n",
    "#     .to_csv(\"3_SARIMAX_holdout_predictions_with_retraining.csv\", index=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = root_mean_squared_error(\n",
    "#     y_pred=pl.read_csv(\"3_SARIMAX_holdout_predictions_with_retraining.csv\")[\"pred\"],\n",
    "#     y_true=pl.read_csv(\"3_SARIMAX_holdout_predictions_with_retraining.csv\")[\"kWh\"],\n",
    "# )\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.concat(model_coefs_list, how=\"vertical\").to_pandas().to_csv(\n",
    "#     \"3_SARIMAX_holdout_model_coefficients.csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the figure with step lines for both actual and predicted values\n",
    "# fig = px.line(\n",
    "#     pd.concat(y_preds_list).reset_index(),\n",
    "#     x=\"datetime\",\n",
    "#     y=[\"kWh\", \"pred\"],\n",
    "#     labels={\n",
    "#         \"datetime\": \"Date\",\n",
    "#         \"value\": \"Energy Consumption (kWh)\",\n",
    "#         \"variable\": \"Series\",\n",
    "#     },\n",
    "#     title=\"Actual vs Predicted Energy Consumption Over Time\",\n",
    "#     line_shape=\"hv\",  # Set line shape to horizontal-vertical for step chart\n",
    "# )\n",
    "\n",
    "# # Customize the layout\n",
    "# fig.update_layout(\n",
    "#     template=\"plotly_white\",\n",
    "#     legend=dict(title=\"\"),\n",
    "#     xaxis_title=\"Date\",\n",
    "#     yaxis_title=\"Energy Consumption (kWh)\",\n",
    "# )\n",
    "\n",
    "# # Show the figure\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lapro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
